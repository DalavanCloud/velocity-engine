/*
 * The Apache Software License, Version 1.1
 *
 * Copyright (c) 2000 The Apache Software Foundation.  All rights
 * reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in
 *    the documentation and/or other materials provided with the
 *    distribution.
 *
 * 3. The end-user documentation included with the redistribution, if
 *    any, must include the following acknowlegement:
 *       "This product includes software developed by the
 *        Apache Software Foundation (http://www.apache.org/)."
 *    Alternately, this acknowlegement may appear in the software itself,
 *    if and wherever such third-party acknowlegements normally appear.
 *
 * 4. The names "The Jakarta Project", "Tomcat", and "Apache Software
 *    Foundation" must not be used to endorse or promote products derived
 *    from this software without prior written permission. For written
 *    permission, please contact apache@apache.org.
 *
 * 5. Products derived from this software may not be called "Apache"
 *    nor may "Apache" appear in their names without prior written
 *    permission of the Apache Group.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
 * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
 * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 * ====================================================================
 *
 * This software consists of voluntary contributions made by many
 * individuals on behalf of the Apache Software Foundation.  For more
 * information on the Apache Software Foundation, please see
 * <http://www.apache.org/>.
 */

options
{
    /** The default package for this parser kit */
    NODE_PACKAGE="org.apache.velocity.runtime.parser";

    /** A source file will be generated for each non-terminal */
    MULTI=true;
    
    /**
     * Each node will have access to the parser, I did this so
     * some global information can be shared via the parser. I
     * think this will come in handly keeping track of
     * context, and being able to push changes back into
     * the context when nodes make modifications to the
     * context by setting properties, variables and
     * what not.
     */
    NODE_USES_PARSER=true;
    
    /**
     * The parser must be non-static in order for the
     * above option to work, otherwise the parser value
     * is passed in as null, which isn't all the useful ;)
     */
    STATIC=false;
    
    /**
     * Enables the use of a visitor that each of nodes
     * will accept. This way we can separate the logic
     * of node processing in a visitor and out of the
     * nodes themselves. If processing changes then
     * the nothing has to change in the node code.
     */
    VISITOR=true;
    
    /**
     * This option is used as one of the steps
     * required to allow the use of an "#include"
     * type behaviour. In this case the directive
     * is "#parse". See the TOKEN_MGR_DECLS section
     * below for details on how the TokenManager is
     * modified to allow this behaviour.
     */
    COMMON_TOKEN_ACTION=true;
    
    DEBUG_PARSER=false;
    DEBUG_TOKEN_MANAGER=false;
}    

PARSER_BEGIN(Parser)

package org.apache.velocity.runtime.parser;

import java.io.*;
import java.util.*;

import org.apache.velocity.runtime.parser.node.*;
import org.apache.velocity.runtime.directive.Directive;

/**
 * This class is responsible for parsing a Velocity
 * template. This class was generated by JavaCC using
 * the JJTree extension to produce an Abstract
 * Syntax Tree (AST) of the template.
 *
 * Please look at the Parser.jjt file which is
 * what controls the generation of this class.
 *
 * @author <a href="mailto:jvanzyl@periapt.com">Jason van Zyl</a>
 * @author <a href="mailto:geirm@optonline.net">Geir Magnusson Jr.</a>
 * @version $Id: Parser.jjt,v 1.12 2000/11/01 01:10:34 geirm Exp $ 
*/
public class Parser
{
    
    
    Hashtable directives;
    
    /* This was added to allow the parser to be associated
     * with a particular syntax. JavaCC doesn't generate
     * a constructor without parameters. The normal constructor
     * takes a single argument which an InputStream. But in
     * order to make the parser dynamically loadable this
     * constructor had to be added. This also allows us to
     * create a single instance of a parser and reuse
     * it over and over.
     */
    public Parser()
    {
        this(new ByteArrayInputStream("\n".getBytes()));
    }

    /* This was also added to allow parsers to be dynamically
     * loadable.
     * 
     * Taken from the generated constructor in Parser.java.
     * Just be watchful when you change the grammar because
     * the generated method changes when the grammar changes
     * WRT to adding new token types. So you have to
     * occasionally do some cutting and pasting :-)
     *
     * It would be A LOT better it you could subclass grammars
     * and override particular methods but that's not
     * possible with JavaCC. I believe that you can do
     * this with ANTLR though.
     */
    public SimpleNode parse(InputStream stream) throws ParseException
    {
        token_source.clearStateVars();
        ReInit(stream);  
       // return process();
    
        SimpleNode n = null;

        try {
            n = process();
        } catch (Exception e) { System.out.println(e);}

        return n;
    }        

    public void setDirectives(Hashtable directives)
    {
        this.directives = directives;
    }

    public Directive getDirective(String directive)
    {
        return (Directive) directives.get(directive);
    }

    public boolean isDirective(String directive)
    {
        if (directives.containsKey(directive))
            return true;
        else
            return false;
    }            
}

PARSER_END(Parser)

/**
 * This gets inserted into the ParserMacroTokenManager
 * and is being used here strictly for the #parse
 * directive: an #include type behaviour. We have
 * to save the state the stream currently being
 * parsed and we have to save the state of the
 * lexer (TokenManager class) then we create
 * a new stream from the file named in the
 * #parse directive then we ReInit the lexer. 
 * Whatever it parses will get placed 
 * into the AST.
 *
 * I need a simple way to detect circular
 * inclusions so this thing doesn't go wild
 * and drag down the VM.
 */
TOKEN_MGR_DECLS: 
{  
    private boolean incMode;
    private int fileDepth = 0;

    private int lparen = 0;
    private int rparen = 0;

    Stack stateStack = new Stack();
    public boolean bDebugPrint_ = false;

    private boolean inReference;
    public boolean inDirective;
    private boolean inComment;
    private boolean inSet;

    Stack streams = new Stack();
    Stack states = new Stack();
    
    // remove double quotes in the string
    String stripQuotes(String str) 
    {
        int start = str.indexOf("\"");
        int end = str.indexOf("\"",start+1);    
        return str.substring(start+1,end);
    }    
    
    /**
     * Save the state of the current input stream
     * and the state of the lexer. So we can process
     * the new one.
     */
    void pushFile(String filename)
    {
        fileDepth++;
        
        streams.push(input_stream);
        states.push(new Integer(curLexState));
        
        try
        {
            FileInputStream fs = new FileInputStream(filename);
            ASCII_CharStream new_stream = new ASCII_CharStream(fs,1,1);    
            ReInit(new_stream);
        }
        catch(Exception e)
        {
        }
    }    
  
    /**
     * Retrieve the oldStream and oldState and
     * continue processing the input.
     */
    void popFile()
    {
        ReInit((ASCII_CharStream) streams.pop(), ((Integer) states.pop()).intValue());
        fileDepth--;
    }    
    
    private boolean AtParent()
    {
        if (fileDepth == 0)
            return true;
        else
            return false;
    }
    
    void CommonTokenAction(Token t)
    {
        if (t.kind == EOF && ! AtParent())
        {
            Token new_t;
            popFile();
            new_t = getNextToken();
            t.kind = new_t.kind;
            t.beginLine = new_t.beginLine;
            t.beginColumn = new_t.beginColumn;
            t.endLine = new_t.endLine;
            t.endColumn = new_t.endColumn;
            t.image = new_t.image;
            t.next = new_t.next;
            t.specialToken = new_t.specialToken;
        }
    } 

    /**
     *  pushes the current state onto the 'state stack',
     *  and maintains the parens counts
     *  public because we need it in PD & VM handling
     *
     *  @return boolean : success.  It can fail if the state machine
     *     gets messed up.
     */
    public boolean stateStackPop()
    {
      
        Hashtable hStack;

        try
        {
            hStack = (Hashtable) stateStack.pop();
        }
        catch( EmptyStackException e)
        {
            lparen=0;
            SwitchTo(DEFAULT);
            return false;
        }

        if( bDebugPrint_ )
            System.out.println(" stack pop (" + stateStack.size() + ") : lparen=" + ( (Integer) hStack.get("lparen")).intValue() 
                + " newstate=" +  ( (Integer)  hStack.get("lexstate")).intValue() );
       
        lparen = ( (Integer) hStack.get("lparen")).intValue();
        rparen = ( (Integer) hStack.get("rparen")).intValue();
        SwitchTo( ( (Integer) hStack.get("lexstate")).intValue() ); 
    
        return true;
    }

    /**
     *  pops a state off the stack, and restores paren counts
     *
     *  @return boolean : success of operation
     */
    public boolean stateStackPush()
    {
        if( bDebugPrint_ )
            System.out.println(" (" + stateStack.size() + ") pushing cur state : " + curLexState );
            
        Hashtable hStack = new Hashtable();
        hStack.put("lexstate", new Integer( curLexState ) );
        hStack.put("lparen", new Integer( lparen ));
        hStack.put("rparen", new Integer( rparen ));
        lparen = 0;

        stateStack.push( hStack );

        return true;
    }

    /**
     *  Clears all state variables, resets to
     *  start values, clears stateStack.  Call
     *  before parsing.
     *  @return void
     */   
    public void clearStateVars()
    {
        stateStack.clear();
        
        lparen = 0;
        rparen = 0;
        inReference = false;
        inDirective = false;
        inComment = false;
        inSet = false;
        
        return;
    }


    /**
     *  handles the dropdown logic when encountering a RPAREN
     */
    private void RPARENHandler()
    {
        /*
         *  Ultimately, we want to drop down to the state below the one that has an open (
         *  if we hit bottom (DEFAULT), that's fine. It's just text schmoo.
         *
         */
   
        boolean bClosed = false;

        if (inComment)
            bClosed = true;

        while( !bClosed) 
        {
            /*
             * look at current state.  If we haven't seen a lparen in this state
             * then we drop a state, because this lparen clearly closes our state
             */

            if( lparen > 0)
            {
                /*
                 *  if rparen + 1 == lparen, then this state is closed. Otherwise, increment
                 *  and keep parsing
                 */

                 if( lparen == rparen + 1)
                 {
                       stateStackPop();
                 }  
                else
                {   
                    rparen++;
                }
                      
                 bClosed = true;
            }
            else
            {
                /*
                 * now, drop a state
                 */
        
                if(!stateStackPop())
                    break;
            } 
        }
    }
} 

/* ------------------------------------------------------------------------
 *
 * Tokens
 *
 *  Note : we now have another state, REFMODIFIER.  This is sort of a 
 *  type of REFERENCE state, simply use to use the DIRECTIVE token
 *  set when we are processing a $foo.bar() construct
 *
 * ------------------------------------------------------------------------- */

<DIRECTIVE,REFMODIFIER,REFMOD2>
TOKEN:
{ 
    <LBRACKET: "[">
|   <RBRACKET: "]">
}

<DIRECTIVE,REFMOD2>
TOKEN:
{
    <COMMA:",">
}

<DIRECTIVE,REFMODIFIER>
TOKEN:
{
    <LPAREN: "(">
    {
        if (!inComment)
            lparen++;

        /*
         *  if we have seen the dot, then move to REFMOD2 -> Modifier()
         */

        if (curLexState == REFMODIFIER )
            SwitchTo( REFMOD2 );

    }

|   <RPAREN: ")" (" ")* ("\n")?>
    {
       RPARENHandler();
    }    
}

/*
 *  in REFMOD2, we don't want to bind the whitespace and \n like we do when closing a directive.
 */
<REFMOD2>
TOKEN:
{
    <REFMOD2_RPAREN: ")">
    {
       RPARENHandler();
    }    
}

<*>
MORE :
{
    //
    //  Note : DOLLARBANG is a duplicate of DOLLAR.  They must be identical.
    //

    <DOLLAR: "$"> 
    { 
        if (! inComment)
        {
            inReference = true;

           if ( bDebugPrint_ )
                System.out.print( "$  : going to " + REFERENCE );

            stateStackPush();
            SwitchTo(REFERENCE);
        }            
    }

|   <DOLLARBANG: "$!"> 
    { 
        if (! inComment)
        {
            inReference = true;

           if ( bDebugPrint_ )
                System.out.print( "$!  : going to " + REFERENCE );

            stateStackPush();
            SwitchTo(REFERENCE);
        }            
    }

|   "##"
   { 
        inComment = true;
        stateStackPush();
        SwitchTo(IN_SINGLE_LINE_COMMENT);
     }

|   <"#**" ~["#"]> 
    { 
        input_stream.backup(1); 
        inComment = true; 
        stateStackPush();
        SwitchTo( IN_FORMAL_COMMENT);
        // was : IN_FORMAL_COMMENT
    } 
    
|   "#*" 
    { 
        inComment=true;
        stateStackPush();
        SwitchTo( IN_MULTI_LINE_COMMENT ); 
    } 


|   <HASH : "#"> 
  { 
        if (! inComment)
        {
            inDirective = true;

            if ( bDebugPrint_ )
                System.out.print("# :  going to " + DIRECTIVE );
            
            stateStackPush();
            SwitchTo(DIRECTIVE);
        }
    } 
}   

TOKEN :
{
    <ESCAPE_SEQUENCE: "\\" ~[] >
|   <TEXT: (~["$", "#", "\\"])+ >
}    


// -----------------------------------------------------------------------
// 
// COMMENT Lexical States
// 
// -----------------------------------------------------------------------

<IN_SINGLE_LINE_COMMENT>
TOKEN :
{
  <SINGLE_LINE_COMMENT: "\n" | "\r" | "\r\n" > 
  { 
     inComment = false;
     stateStackPop();
    // was :DEFAULT
  } 

}

<IN_FORMAL_COMMENT>
TOKEN :
{
  <FORMAL_COMMENT: "*#" > 
  {     
    inComment = false;
    stateStackPop();
    // was :DEFAULT
  } 
}

<IN_MULTI_LINE_COMMENT>
TOKEN :
{
  <MULTI_LINE_COMMENT: "*#" > 
  { 
    inComment = false; 
    stateStackPop();
    // was :DEFAULT
  } 
}

<IN_SINGLE_LINE_COMMENT,IN_FORMAL_COMMENT,IN_MULTI_LINE_COMMENT>
MORE :
{
  < ~[] >
}

// -----------------------------------------------------------------------
// 
// DIRECTIVE Lexical State
// 
// -----------------------------------------------------------------------

<DIRECTIVE,REFMOD2> 
SKIP:
{
    " "
|   "\t"
//|   "\n"
//|   "\r"
}

<REFERENCE,DIRECTIVE,REFMODIFIER,REFMOD2>
TOKEN :
{

   <STRING_LITERAL: ( "\"" ( ~["\"","\n","\r"] )* "\"" ) >
    {
        if (incMode)
        {
            matchedToken.image = stripQuotes(image.toString());
            pushFile(matchedToken.image);
        }
        incMode = false;
    
       // from jason :
       // if (lparen == 0)
       //     SwitchTo(DEFAULT);
    
        /*
         *  - if we are in REFERENCE || REFMODIFIER then " is an ender
         *  - if we are in DIRECTIVE and haven't seen ( yet, then also drop out. 
         *      don't forget to account for the beloved yet wierd #set
         *  - finally, if we are in REFMOD2 (remember : $foo.bar( ) then " is ok!
         */

        if (curLexState == REFERENCE || curLexState == REFMODIFIER)
            stateStackPop();
        else if( curLexState == DIRECTIVE && !inSet && lparen == 0)
            stateStackPop();    

    }

|   <TRUE: "true">
|   <FALSE: "false">
}

<DIRECTIVE>
TOKEN :
{
    <NEWLINE: "\n" | "\r" | "\r\n" >
    {
        if ( bDebugPrint_ )
            System.out.println(" NEWLINE :");

        stateStackPop();      
        
        if (inSet)
            inSet = false;
        
        if (inDirective)
            inDirective = false;
    }        
}    

<DIRECTIVE>
TOKEN : 
{
    <MINUS: "-">
|   <PLUS: "+">
|   <MULTIPLY: "*">
|   <DIVIDE: "/">
|   <MODULUS: "%">
|   <LOGICAL_AND: "&&">
|   <LOGICAL_OR: "||">
|   <LOGICAL_LT: "<">
|   <LOGICAL_LE: "<=">
|   <LOGICAL_GT: ">">
|   <LOGICAL_GE: ">=">
|   <LOGICAL_EQUALS: "==">
|   <LOGICAL_NOT_EQUALS: "!=">
|   <LOGICAL_NOT: "!">
|   <EQUALS: "=" >
}

<DIRECTIVE> 
TOKEN :
{
    <END: "end" ("\n")?> 
    { 
        inDirective = false; 
        stateStackPop();
    } 

|   <INCLUDE_DIRECTIVE: "include"> 
    { incMode = true; }

|   <IF_DIRECTIVE: "if">

|   <ELSEIF_DIRECTIVE: "elseif">

|   <ELSE_DIRECTIVE: "else"> 
     { 
        inDirective = false; 
        stateStackPop();
    } 

|   <SET_DIRECTIVE: "set" >
    { inSet = true; }

|   <STOP_DIRECTIVE: "stop">
    {
        matchedToken.kind = EOF;
        fileDepth = 0;
    }

|   <#DIGIT: [ "0"-"9" ] >
|   <NUMBER_LITERAL: (<DIGIT>)+ >
    {
        //!!! fixed <bcolor="#333333"/>
        // needs to be more thorough.
       // if (lparen == 0)
       //     SwitchTo(DEFAULT);
    }            
    
    //!!! fixed #FFFFFF
|   <#LETTER: [ "a"-"z", "A" - "Z" ] >
|   <WORD: (<LETTER>)+ >
}


// -----------------------------------------------------------------------
// 
// REFERENCE Lexical State
// 
// -----------------------------------------------------------------------

<REFERENCE,REFMODIFIER,REFMOD2> 
TOKEN :
{
    <#ALPHA_CHAR: ["a"-"z", "A"-"Z"] >
|   <#ALPHANUM_CHAR: [ "a"-"z", "A"-"Z", "0"-"9" ] >
|   <#IDENTIFIER_CHAR: [ "a"-"z", "A"-"Z", "0"-"9", "-", "_" ] >
|   <IDENTIFIER:  <ALPHA_CHAR> (<IDENTIFIER_CHAR>)* >
|   <DOT: "." <ALPHA_CHAR>> 
    { 
        /*
         * push the alpha char back into the stream so the following identifier is complete
         */

        input_stream.backup(1); 

        /*
         *  and munge the <DOT> so we just get a . when we have normal text that looks like a ref.ident
         */

        matchedToken.image = ".";

        if ( bDebugPrint_ ) 
            System.out.print("DOT : switching to " + REFMODIFIER); 
        SwitchTo(REFMODIFIER); 

    }
|   <LCURLY: "{">
|   <RCURLY: "}">
    {
        // was :DEFAULT
        stateStackPop();
    }
}

<REFERENCE,REFMODIFIER,REFMOD2> 
SPECIAL_TOKEN :
{
    <REFERENCE_TERMINATOR: ~[] >
    {   
        /*
         *  These can terminate a reference, but are needed in subsequent states
         */

        if (image.toString().equals("=") || image.toString().equals("\n"))
        {
            input_stream.backup(1);
        } 
                
        inReference = false;
    
        if ( bDebugPrint_ )
            System.out.print("REF_TERM :");
        
        stateStackPop();

        /*
         *  I removed LPAREN & RPAREN from REFERENCE;  as there is no LPAREN,RPAREN in REF is there is REFMETHOD
         */
        
        if (curLexState != DEFAULT && ( image.toString().equals(")") 
                                        || image.toString().equals(",") 
                                        || image.toString().equals("[") 
                                        || image.toString().equals("]")
                                        ) )
        {
            input_stream.backup(1);
        }

    }
}

/**
 * This method is what starts the whole parsing
 * process. After the parsing is complete and
 * the template has been turned into an AST,
 * this method returns the root of AST which
 * can subsequently be traversed by a visitor
 * which implements the ParserVisitor interface
 * which is generated automatically by JavaCC
 */
SimpleNode process() : {}
{
   ( Statement() )* <EOF>
   { return jjtThis; }
}

// -----------------------------------------------------------------------
// 
// Statement Syntax
// 
// -----------------------------------------------------------------------

/**
 * These are the types of statements that
 * are acceptable in Velocity templates.
 * I have not found that the order here
 * matters much. Someone please correct
 * me here if I'm wrong.
 */

void Statement() #void : {}
{
   IfStatement()
|   IncludeStatement()
|   StopStatement()
|   Reference()
|   Comment()
|   SetDirective()
|   Directive()
|   Text()
}

void Comment() : {}
{
    <SINGLE_LINE_COMMENT>
|   <MULTI_LINE_COMMENT>
|   <FORMAL_COMMENT>
}

void NumberLiteral() : {}
{
    <NUMBER_LITERAL>
}    

void StringLiteral() : {}
{
    <STRING_LITERAL>
}    

/**
 * This method corresponds to variable
 * references in Velocity templates.
 * The following are examples of variable
 * references that may be found in a
 * template:
 *
 * $foo
 * $bar
 *
 */
void Identifier() : {}
{    
    <IDENTIFIER>
}

void Word() : {}
{
    <WORD>
}    

void DirectiveArg() #void : {}
{
    Reference()
|   Word()  
|   StringLiteral()
|   NumberLiteral()
|   ObjectArray()
}

SimpleNode Directive() : 
{
    Token t;
    Directive d;
}
{
    t = <WORD>
    {
        d = (Directive) directives.get(t.image.substring(1));
        
        if (d == null)
        {
            token_source.stateStackPop();
            token_source.inDirective = false;
            return jjtThis;
        }            
    }

    <LPAREN> (DirectiveArg())+ <RPAREN>
    {
        if (d.getType() == Directive.LINE)
            return jjtThis;
    }
    
    ( Statement() )+ #Block 
    <END>
    {
        return jjtThis;
    } 
}    

void ObjectArray() : {}
{
    <LBRACKET> [ Parameter() ( <COMMA> Parameter() )* ] <RBRACKET>
}

/**
 * This method has yet to be fully implemented
 * but will allow arbitrarily nested method
 * calls
 */
void Parameter() #void: {}
{
    StringLiteral()
|   ObjectArray()
|   True()
|   False()
|   Reference() 
}

/**
 * This method has yet to be fully implemented
 * but will allow arbitrarily nested method
 * calls
 */
void Method() : {}
{
    Identifier() <LPAREN> [ Parameter() ( <COMMA> Parameter() )* ] <REFMOD2_RPAREN>
}

void Reference() : {}
{ 

    // This should be changed to Indentifier() now. Make
    // it easier to walk the AST.
    [<LCURLY>]
    <IDENTIFIER>
    [<RCURLY>]
    (LOOKAHEAD(2) <DOT> (LOOKAHEAD(3) Method() | Identifier() ) [<RCURLY>] )*
}

void True() : {}
{
    <TRUE>
}

void False() : {}
{
    <FALSE>
}

/**
 * This method is responsible for allowing
 * all non-grammar text to pass through
 * unscathed.
 */
void Text() : 
{
    Token t;
}
{
    <TEXT>
|   <NEWLINE>  
|   <DOT>
|   <RPAREN>
|   <LPAREN>
|   <NUMBER_LITERAL>
|   <STRING_LITERAL>
|   t = <ESCAPE_SEQUENCE>
    {
        t.image = t.image.substring(1);
    }      

}

// -----------------------------------------------------------------------
// 
// Directive Syntax
// 
// -----------------------------------------------------------------------

void IfStatement() : {}
{
     <IF_DIRECTIVE> <LPAREN> Expression() <RPAREN>
    ( Statement() )+ #Block
    [ LOOKAHEAD(1) ( ElseIfStatement() )+ ]
    [ LOOKAHEAD(1) ElseStatement() ]
    <END>
}

void ElseStatement() : {}
{
    <ELSE_DIRECTIVE> 
    ( Statement() )+ #Block
}

void ElseIfStatement() : {}
{
    <ELSEIF_DIRECTIVE> 
    <LPAREN> Expression() <RPAREN>
    ( Statement() )+ #Block
}

void SetDirective() : {}
{
   ( <SET_DIRECTIVE> Expression() [<NEWLINE>] )
}    

/**
 * This method corresponds to an #include
 * directive in a Velocity template. The
 * following are examples of #include
 * constructs that are acceptable in
 * a template:
 *
 * #include "foo.inc" 
 */
void IncludeStatement() #void: {}
{
    <INCLUDE_DIRECTIVE> <STRING_LITERAL>
}

/**
 * This method corresponds to the #stop
 * directive which just simulates and EOF
 * so that parsing stops. The #stop directive
 * is really only useful for debugging
 * purposes.
 */
void StopStatement() #void: {}
{    
    <STOP_DIRECTIVE>
}

// -----------------------------------------------------------------------
// 
// Expression Syntax
// 
// -----------------------------------------------------------------------

void Expression() : {}
{
    LOOKAHEAD( PrimaryExpression() <EQUALS> ) Assignment()
|   ConditionalOrExpression()
}

void Assignment() #Assignment(2) : {}
{
    PrimaryExpression() <EQUALS> Expression()
}

void ConditionalOrExpression() #void : {}
{
  ConditionalAndExpression()
  ( <LOGICAL_OR> ConditionalAndExpression() #OrNode(2) )*
}


void ConditionalAndExpression() #void : {}
{
  EqualityExpression()
  ( <LOGICAL_AND>  EqualityExpression() #AndNode(2) )*
}

void EqualityExpression() #void : {}
{
    RelationalExpression()
    (
          <LOGICAL_EQUALS> RelationalExpression()     #EQNode(2)
        | <LOGICAL_NOT_EQUALS> RelationalExpression() #NENode(2)
    )*
}

void RelationalExpression() #void : {}
{
    AdditiveExpression()
    (
          <LOGICAL_LT> AdditiveExpression() #LTNode(2)
        | <LOGICAL_GT> AdditiveExpression() #GTNode(2)
        | <LOGICAL_LE> AdditiveExpression() #LENode(2)
        | <LOGICAL_GE> AdditiveExpression() #GENode(2)
    )*
}

void AdditiveExpression() #void : {}
{
    MultiplicativeExpression()
    (
          <PLUS>  MultiplicativeExpression() #AddNode(2)
        | <MINUS> MultiplicativeExpression() #SubtractNode(2)
    )*
}

void MultiplicativeExpression() #void : {}
{
    UnaryExpression()
    (
          <MULTIPLY> UnaryExpression() #MulNode(2)
        | <DIVIDE>   UnaryExpression() #DivNode(2)
        | <MODULUS>  UnaryExpression() #ModNode(2)
    )*
}

void UnaryExpression() #void : {}
{
    <LOGICAL_NOT> UnaryExpression() #NotNode(1)
|   PrimaryExpression()
}

void PrimaryExpression() #void : {}
{    
    StringLiteral()
|   NumberLiteral()    
|   Reference()
|   ObjectArray()
|   True()
|   False()
|   <LPAREN> Expression() <RPAREN>
}
